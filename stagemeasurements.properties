master=local[*]
#master=yarn

uuid.filename.sufix=false

input.file.name=/opt/newsynt.csv
input.file.name.join=/opt/newsynt-split.csv
output.file.name=/opt/newsynt-out.csv

format=csv
hive.support=false
spark.parallel.threads=2

stage.flow=WRITE:
#stage.flow=GROUP:NIN
#stage.flow=GROUP:NIN, WRITE:
#stage.flow=GROUP:PARTITIONER
#stage.flow=GROUP:PARTITIONER, WRITE:

#stage.flow=JOIN:ADDRESS
#stage.flow=JOIN:NIN
#stage.flow=JOIN:PARTITIONER

#stage.flow=JOIN:ADDRESS, WRITE:
#stage.flow=JOIN:NIN, WRITE:
#stage.flow=JOIN:PARTITIONER, WRITE:

#stage.flow=CUBE:NIN
#stage.flow=CUBE:PARTITIONER
#stage.flow=CUBE:NIN, WRITE:
#stage.flow=CUBE:PARTITIONER, WRITE:

#stage.flow=GROUP:NIN, JOIN:ADDRESS, CUBE:NIN
#stage.flow=GROUP:NIN, JOIN:ADDRESS, CUBE:NIN, WRITE:
#stage.flow=GROUP:PARTITIONER, JOIN:ADDRESS, CUBE:PARTITIONER
#stage.flow=GROUP:PARTITIONER, JOIN:ADDRESS, CUBE:PARTITIONER, WRITE:

partitioned=false
partition.field.name=NIN

date.present=true
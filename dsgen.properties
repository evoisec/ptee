master=local[*]
#master=yarn

hive.support=false
spark.parallel.threads=2

start.year=2018
start.month=1
start.day=1
end.year=2020
end.month=1
end.day=1

uuid.filename.sufix=true
storage=file
format=csv
file.name=/opt/synt22.csv
#format=parquet
#storage=db
db.name=perf_testing
table.name=synt
#dwh.location=/opt/dwh
dwh.location=/user/hive/warehouse

name.string.len=8
address.string.len=12
nin.int.len=10
benefits.int.len=1000
accname.int.len=30

partitioned=false
partition.field.name=NIN

initial.record.count1=5
outer.iterations1=5
inner.iterations1=2

#5 x (2 pow 5) = 160

#################################################################################################################
# Use Mainly the Following 2 params to adjust the total number of records
# the reson to prefer them is that they guide the record generation on the cluster nodes ie not on the driver
#################################################################################################################

outer.iterations2=2
inner.iterations2=3

# use mainly the above two parameters to set the total number of records
# the formula is:
# 160x(inner.iterations2 pow outer.iterations2)  or 160 x (3 pow 2) = 1440 (note there is also 1 extra row for dataset header hence the total is 1441)
# the data size of a single record is about 0.180K

############################################################################################################################
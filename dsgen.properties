master=local[*]
#master=yarn

hive.support=false
spark.parallel.threads=2

start.year=2018
start.month=1
start.day=1
end.year=2020
end.month=1
end.day=1

storage=file
format=csv
#format=parquet
#storage=db
db.name=perf_testing
table.name=synt
file.name=/opt/synt.csv

name.string.len=8
address.string.len=12
nin.int.len=10
benefits.int.len=1000
accname.int.len=30

partitioned=false
partition.field.name=NIN

initial.record.count1=5
outer.iterations1=5
inner.iterations1=2

#5 x (2 pow 5) = 160

######################################################

outer.iterations2=2
inner.iterations2=3

# use mainly the above two parameters to set the total number of records
# the formula is:
# 160x(inner.iterations2 pow outer.iterations2)  or 160 x (3 pow 2) = 1440 (note there is also 1 extra row for dataset header hence the total is 1441)

######################################################

#0.029K per record